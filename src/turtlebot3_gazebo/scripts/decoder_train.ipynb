{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from decoder_net import ImageNet, RangeNet, DataSet\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "print('Device: ', device)\n",
    "\n",
    "net = RangeNet()\n",
    "\n",
    "data = DataSet('warehouse')\n",
    "\n",
    "# epoch_loss, batch_loss = net.train_net(net, data, device, 1, 1000)\n",
    "\n",
    "net.load_state_dict(torch.load('trained_conv_nets/rng/warehouse1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranges(ranges):\n",
    "    ranges = ranges.detach().numpy().flatten()\n",
    "    ranges_x = []\n",
    "    ranges_y = []\n",
    "    for i, r in enumerate(ranges):\n",
    "        ranges_x.append(r * math.cos(math.radians(i + 1)))\n",
    "        ranges_y.append(r * math.sin(math.radians(i + 1)))\n",
    "\n",
    "    return ranges_x, ranges_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_office_rng = data.X_test\n",
    "\n",
    "ranges_pred = net(data.X_test)\n",
    "ranges_true = data.Y_rng_test\n",
    "\n",
    "ranges_pred_x, ranges_pred_y = plot_ranges(ranges_pred[200])\n",
    "ranges_true_x, ranges_true_y = plot_ranges(ranges_true[200])\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "axs[0].scatter(ranges_pred_x, ranges_pred_y)\n",
    "axs[1].scatter(ranges_true_x, ranges_true_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1464, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960,\n",
       "         2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964,\n",
       "         2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960,\n",
       "         2.1964, 2.1960, 2.5002, 2.5013, 2.8495, 2.8489, 2.8002, 2.7994, 2.8423,\n",
       "         2.8422, 2.6019, 2.5997, 2.1964, 2.1960, 3.0212, 3.0249, 3.9694, 3.9685,\n",
       "         3.8355, 3.8342, 3.9498, 3.9503, 3.2973, 3.2919, 2.1964, 2.1960, 2.8835,\n",
       "         2.8865, 3.6734, 3.6725, 3.5618, 3.5606, 3.6570, 3.6573, 3.3033, 3.2996,\n",
       "         2.6044, 2.6039, 3.2440, 3.2467, 4.0410, 4.0404, 3.7819, 3.7797, 3.6215,\n",
       "         3.6218, 4.0593, 4.0596, 4.2775, 4.2765, 4.1203, 4.1189, 4.2545, 4.2551,\n",
       "         4.4865, 4.4851, 4.3415, 4.3405, 4.1795, 4.1780, 4.3178, 4.3184, 4.0947,\n",
       "         4.0910, 3.4138, 3.4131, 3.9581, 3.9602, 4.7679, 4.7678, 4.2166, 4.2120,\n",
       "         3.5488, 3.5491, 4.2783, 4.2801, 4.8464, 4.8453, 4.6462, 4.6445, 4.8171,\n",
       "         4.8180, 5.0081, 5.0060, 4.7034, 4.7023, 4.5140, 4.5124, 4.6757, 4.6765,\n",
       "         5.2212, 5.2209, 5.3523, 5.3510, 5.1139, 5.1119, 5.3174, 5.3185, 5.6875,\n",
       "         5.6857, 5.4886, 5.4873, 5.2399, 5.2379, 5.4522, 5.4534, 5.6996, 5.6971,\n",
       "         5.3327, 5.3314, 5.0957, 5.0938, 5.2980, 5.2991, 5.6097, 5.6077, 5.3477,\n",
       "         5.3464, 5.1096, 5.1076, 5.3128, 5.3139, 5.6880, 5.6862, 5.4959, 5.4946,\n",
       "         5.2466, 5.2446, 5.4594, 5.4606, 5.9741, 5.9729, 5.9131, 5.9117, 5.6323,\n",
       "         5.6301, 5.8720, 5.8734, 5.8582, 5.8540, 5.1071, 5.1059, 6.2311, 6.2359,\n",
       "         7.9636, 7.9639, 6.6742, 6.6641, 5.0531, 5.0541, 5.4276, 5.4261, 5.2866,\n",
       "         5.2853, 5.9291, 5.9315, 7.1354, 7.1360, 6.4957, 6.4888, 5.4340, 5.4341,\n",
       "         6.3849, 6.3871, 7.3137, 7.3129, 6.5236, 6.5175, 5.9119, 5.9133, 4.5291,\n",
       "         4.5181, 2.1964, 2.1960, 4.2482, 4.2579, 6.6070, 6.6054, 6.2738, 6.2712,\n",
       "         6.5582, 6.5599, 6.8677, 6.8643, 6.3509, 6.3493, 6.0370, 6.0346, 6.3049,\n",
       "         6.3065, 6.5754, 6.5721, 6.0645, 6.0630, 6.1550, 6.1546, 6.8444, 6.8456,\n",
       "         7.1549, 7.1520, 6.8712, 6.8701, 6.2767, 6.2721, 6.0148, 6.0163, 6.5859,\n",
       "         6.5844, 6.4785, 6.4769, 6.1550, 6.1525, 6.4311, 6.4328, 6.8181, 6.8152,\n",
       "         6.4158, 6.4142, 6.0970, 6.0945, 6.3691, 6.3707, 6.3869, 6.3823, 5.5726,\n",
       "         5.5713, 6.1082, 6.1100, 7.2348, 7.2355, 6.4883, 6.4805, 5.2193, 5.2194,\n",
       "         5.7702, 5.7706, 6.2702, 6.2697, 5.5688, 5.5632, 4.9124, 4.9134, 5.5473,\n",
       "         5.5472, 5.7337, 5.7323, 5.4664, 5.4643, 5.6945, 5.6958, 4.8916, 4.8837,\n",
       "         3.2689, 3.2682, 4.6288, 4.6350, 6.3544, 6.3537, 5.7257, 5.7207, 5.2595,\n",
       "         5.2606, 4.1195, 4.1104, 2.1964, 2.1960, 3.7547, 3.7620, 5.5461, 5.5448,\n",
       "         5.2930, 5.2910, 5.5090, 5.5102, 4.8784, 4.8715, 3.4908, 3.4901, 4.1451,\n",
       "         4.1478, 5.0932, 5.0930, 4.4947, 4.4898, 3.7952, 3.7955, 4.5513, 4.5530,\n",
       "         5.1007, 5.0995, 4.8813, 4.8795, 5.0686, 5.0696, 3.9997, 3.9911, 2.1964,\n",
       "         2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960,\n",
       "         2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964,\n",
       "         2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960,\n",
       "         2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 2.1964, 2.1960, 1.3019]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges_pred[200].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Starting training using office data.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "print('Device: ', device)\n",
    "\n",
    "net = ImageNet()\n",
    "\n",
    "data = DataSet('office')\n",
    "\n",
    "epoch_loss, batch_loss = net.train_net_img(net, data, device, 2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.8/site-packages/ipykernel/eventloops.py:106: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "  app.exec_()\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "plt.title('Training of deconv net on office data')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
